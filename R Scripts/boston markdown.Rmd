---
title: "Boston-Models-RMD"
author: "Jordan Grose"
date: "2/28/2021"
output: html_document
---


### Boston Models  

```{r echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
# preprocessing the boston data
# imports


library(data.table)
library(ggplot2)
library(ggthemes)
library(scales)
library(dplyr)
library(glmnet)
library(tidyr)
library(chron)
library(hms)
library(rpart) 
library(rpart.plot)
library(randomForest)
library(tidyverse)
library(caret)
library(ipred)
library(gbm)
library(boot)
theme_set(theme_bw())


##Load dataset
df <- fread("C:/Users/jorda/iCloudDrive/Documents/BU MSBA COURSES/BA810/flights-All_airlines.csv")
df$DAY_OF_MONTH <- as.factor(df$DAY_OF_MONTH)
df$YEAR <- as.factor(df$YEAR)
df$DAY_OF_WEEK <- as.factor(df$DAY_OF_WEEK)



# dropping columns for models
df[,MKT_CARRIER_AIRLINE_ID := NULL]
df[,MKT_CARRIER := NULL]
df[,TAIL_NUM := NULL]
df[,ORIGIN_CITY_NAME := NULL]
df[,ORIGIN_STATE_ABR := NULL]
df[,DEST_CITY_NAME := NULL]
df[,DEST_STATE_ABR := NULL]
df[,DEST_STATE_NM := NULL]
df[,DEP_TIME := NULL]
df[,CRS_ARR_TIME := NULL]
df[,ARR_TIME := NULL]
df[,ARR_DELAY := NULL]
df[,CANCELLED := NULL]
df[,DIVERTED := NULL]
df[,CRS_ELAPSED_TIME := NULL]
df[,ACTUAL_ELAPSED_TIME := NULL]
df[,AIR_TIME := NULL]
df[,DIV_AIRPORT_LANDINGS := NULL]
df[,DIV_REACHED_DEST := NULL]
df[,CODE := NULL]
df[,EARLY_AM := NULL]
df[,AM := NULL]
df[,PM := NULL]
df[,LATE_PM := NULL]



# subsetting for just Boston flights
bos <- df[ORIGIN == "BOS"]



# getting hour buckets from scheduled flight departure
bos$CRS_DEP_TIME <- as.character(bos$CRS_DEP_TIME)
for( i in 1:nrow(bos)){
  x <- bos[i,]
  number_string = nchar(x$CRS_DEP_TIME)
  if(number_string == 3){
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
  }else if(number_string == 2){
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
  }else if(number_string == 1){
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
    bos[i,CRS_DEP_TIME := paste0("0", CRS_DEP_TIME)]
  }
}

d1 <- strptime(bos$CRS_DEP_TIME, format = "%H%M")
d2 <- format(d1, format = "%H:%M:%S")
bos[,CRS_DEP_TIME_Formatted := d2]
bos$CRS_DEP_TIME_Formatted <- as.factor(bos$CRS_DEP_TIME_Formatted)
bos[,CRS_DEP_HOUR := hour(as.hms(as.character(bos$CRS_DEP_TIME_Formatted)))]



### Adding in weather data ###
weather_bos <- fread("C:/Users/jorda/iCloudDrive/Documents/BU MSBA COURSES/BA810/boston-weather.csv")


weather_bos$day <- as.factor(weather_bos$day)
weather_bos$year <- as.factor(weather_bos$year)

boston <- merge(bos, weather_bos, all.x =TRUE, by.x = c('DAY_OF_MONTH','YEAR'), by.y = c('day','year'))
boston[,location := NULL]
boston[, date_time := NULL]

```

Our first model is a Naive Linear Regression to get a baseline of MSE performance for future models.

```{r}
### NAIVE LINEAR REGRESSION ###

yhat <- mean(boston$DEP_DELAY)
boston_NLR <- boston
boston_NLR[, yhat := yhat]

mse.NLR <- mean((boston_NLR$DEP_DELAY - boston_NLR$yhat)^2)
mse.NLR
```

Next we'll try three linear regression models with a different set of predictors in each to get a sense of which predictors lead to better performance.

```{r message=FALSE, warning=FALSE}
### LINEAR REGRESSION ###

set.seed(810)
boston_LM1 <- boston

# train/test split
test_index <- sample(nrow(boston_LM1), 4678) # this represents an 80/20 train/test split on the entire boston dataset
# now split
dd.test <- boston_LM1[test_index,]
dd.train <- boston_LM1[-test_index,]


# LM Formulas
f1 <- as.formula(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph)

f2 <- as.formula(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + visibility + windspeedKmph)

f3 <- as.formula(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DISTANCE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph)



y.train <- dd.train$DEP_DELAY
y.test <- dd.test$DEP_DELAY


# Fitting the LM model
fit.lm1 <- lm(f1, dd.train)   # all predictors
fit.lm2 <- lm(f2, dd.train)   # removing humidity, precip, pressure, temp
fit.lm3 <- lm(f3, dd.train)   # removing airline and destination 


# compute MSEs for training LMs
# LM1
yhat.train.lm1 <- predict(fit.lm1)
mse.train.lm1 <- mean((y.train - yhat.train.lm1)^2)


# LM2
yhat.train.lm2 <- predict(fit.lm2)
mse.train.lm2 <- mean((y.train - yhat.train.lm2)^2)


# LM3
yhat.train.lm3 <- predict(fit.lm3)
mse.train.lm3 <- mean((y.train - yhat.train.lm3)^2)


# Test MSE
# LM1
yhat.test.lm1 <- predict(fit.lm1, dd.test)
mse.test.lm1 <- mean((y.test - yhat.test.lm1)^2)


# LM2
yhat.test.lm2 <- predict(fit.lm2, dd.test)
mse.test.lm2 <- mean((y.test - yhat.test.lm2)^2)


# LM3
yhat.test.lm3 <- predict(fit.lm3, dd.test)
mse.test.lm3 <- mean((y.test - yhat.test.lm3)^2)

```

Results:  
**Train MSE LM1:** `r mse.train.lm1`\
**Train MSE LM2:** `r mse.train.lm2`\
**Train MSE LM3:** `r mse.train.lm3`\
**Test MSE LM1:** `r mse.test.lm1`\
**Test MSE LM2:** `r mse.test.lm2`\
**Test MSE LM3:** `r mse.test.lm3`


While the Train MSE LM1 was our lowest train MSE, the test MSE for this model was still pretty high with MSE of 1803.11. We expect this might be due to multicolinearity among predictors. 
Let's try using Ridge, Lasso and Elastic Net Regressions to control for multicolinearity as we saw our best results in the LA dataset using these models. We will use all relevant predictors for these regressions because LM1 (all predictors) performed best for linear regression.


```{r message=FALSE, warning=FALSE, error=FALSE}
#### RIDGE REGRESSION ####

boston <- boston[, yhat := NULL]
boston_RR <- boston

# Random Train/Test split
boston_RR[, test:=0]
boston_RR[sample(nrow(boston_RR), 4678), test:=1]

RR.test <- boston_RR[test==1]
RR.train <- boston_RR[test==0]


x1.train <- model.matrix(f1, RR.train)[, -1]
y.train <- RR.train$DEP_DELAY


x1.test <- model.matrix(f1, RR.test)[, -1]
y.test <- RR.test$DEP_DELAY


fit.ridge <- cv.glmnet(x1.train, y.train, alpha = 0, nfolds = 10)


# Ridge Train MSE
yhat.train.ridge <- predict(fit.ridge, x1.train, s = fit.ridge$lambda.min)
mse.train.ridge <- mean((y.train - yhat.train.ridge)^2)


# Ridge Test MSE
yhat.test.ridge <- predict(fit.ridge, x1.test, s = fit.ridge$lambda.min)
mse.test.ridge <- mean((y.test - yhat.test.ridge)^2)



#### LASSO REGRESSION ####


fit.lasso <- cv.glmnet(x1.train, y.train, alpha = 1, nfolds = 10)


# Lasso Train MSE
yhat.train.lasso <- predict(fit.lasso, x1.train, s = fit.lasso$lambda.min)
mse.train.lasso <- mean((y.train - yhat.train.lasso)^2)


# Lasso Test MSE
yhat.test.lasso <- predict(fit.lasso, x1.test, s = fit.lasso$lambda.min)
mse.test.lasso <- mean((y.test - yhat.test.lasso)^2)



#### ELASTIC NET ####


fit.net <- cv.glmnet(x1.train, y.train, alpha = 0.5, nfolds = 10)


# Elastic Net Train MSE
yhat.train.net <- predict(fit.net, x1.train, s = fit.net$lambda.min)
mse.train.net <- mean((y.train - yhat.train.net)^2)


# Elastic Net Test MSE
yhat.test.net <- predict(fit.net, x1.test, s = fit.net$lambda.min)
mse.test.net <- mean((y.test - yhat.test.net)^2)

```

Results:  
**Ridge Train MSE:** `r mse.train.ridge`\
**Ridge Test MSE:** `r mse.test.ridge`\
**Lasso Train MSE:** `r mse.train.lasso`\
**Lasso Test MSE:** `r mse.test.lasso`\
**Net Train MSE:** `r mse.train.net`\
**Net Test MSE:** `r mse.test.net`\


The Lasso Regression with Test MSE of 1386.19 (37.2 minutes) was the best performing model. This is consistent with our LA Ridge regressions being our best performing models. Let's now try running Decision Tree and Random Forest models and compare these results with our Lasso Regression MSE.

```{r}
### DECISION TREE ###

# split the dataset into train/test
set.seed(2021)
index=sample(2,nrow(boston),replace = TRUE,prob=c(0.8,0.2))
trainData<-boston[index==1,]  
testData<-boston[index==2,]

# fitting the decision tree
tree <- rpart(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph, data = trainData, method = "anova")
rpart.plot(tree)
plotcp(tree)
tree$cptable

# prune the tree with cp = 0.01
prune.tree <- prune(tree, cp = 0.01)
prp(prune.tree, type = 1, extra = 1, under = TRUE, split.font = 2, varlen = -10)

# evaluate tree performance
pred <- predict(prune.tree, newdata = testData)

mse.tree <- mean((pred - testData$DEP_DELAY ) ^ 2)
print(mse.tree)

Values1 <- data.frame(obs = testData$DEP_DELAY, pred = pred)
defaultSummary(Values1)

```

The Decision Tree yields an MSE of 1339.09 for the Boston dataset, which is our lowest MSE yet! According to the tree, visibility and the time of the flight are the most significant predictors of departure delay. Let's see how three Random Forest models compares.

```{r}
trainData <- na.omit(trainData)

rf_ntree <- randomForest(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph,data = trainData,ntree=500, proximity=TRUE) 
plot(rf_ntree)

rsample.rf=randomForest(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph,data = trainData,ntree=60,mtry=2, proximity=TRUE) 
print(rsample.rf)

rsample.rf=randomForest(DEP_DELAY ~ DAY_OF_MONTH + DAY_OF_WEEK + DEST + DISTANCE + AIRLINE + CRS_DEP_HOUR + humidity + precipMM + pressure + tempC + visibility + windspeedKmph,data = trainData,ntree=100,mtry=3, proximity=TRUE)
print(rsample.rf)

importance(rsample.rf, type=2)
varImpPlot(rsample.rf)

rsample_pred=predict(rsample.rf,testData)
```


Our last Random forest model returns an MSE of 1335.87, our lowest MSE yet. We can see that the optimal number of trees is around 100. We are conscious that increasing the number of trees will result in higher variance in our results going forward, so we want to select a number of trees that both minimizes MSE and keeps Variance as low as possible. We believe this will be 100 trees, with an MSE of 1335.87 (36.5 minutes) based on the Boston data. Again, the random forest model places visibility and departure time as being the most significant predictors for departure delay.







































